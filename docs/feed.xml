<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-12-28T00:29:35-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Stewy Slocum</title><subtitle>Stewy Slocum&apos;s website</subtitle><author><name>Stewart Slocum</name></author><entry><title type="html">Readings</title><link href="http://localhost:4000/2021/12/20/readings.html" rel="alternate" type="text/html" title="Readings" /><published>2021-12-20T00:00:00-05:00</published><updated>2021-12-20T00:00:00-05:00</updated><id>http://localhost:4000/2021/12/20/readings</id><content type="html" xml:base="http://localhost:4000/2021/12/20/readings.html"><![CDATA[<blockquote>
  <p>List of things I’ve been reading. Only adding things that I’ve read thoroughly and understand beyond a superficial level.</p>
</blockquote>

<!--more-->
<h3 id="11422">11/4/22</h3>
<ul>
  <li>Reinforcement Learning by Reward-Weighted Regression for Operational Space Control <a href="https://is.mpg.de/fileadmin/user_upload/files/publications/ICML2007-Peters_4493%5B0%5D.pdf">[link]</a></li>
</ul>

<h3 id="10222022">10/22/2022</h3>
<ul>
  <li>Precis of The Limits of Morality <a href="https://cpb-us-w2.wpmucdn.com/campuspress.yale.edu/dist/7/724/files/2016/01/Precis-of-The-Limits-of-Morality-1344xg3.pdf">[link]</a></li>
</ul>

<h3 id="10202022">10/20/2022</h3>
<ul>
  <li>CHOMP: Covariant Hamiltonian optimization for motion planning <a href="https://journals.sagepub.com/doi/10.1177/0278364913488805">[link]</a></li>
</ul>

<h3 id="10192022">10/19/2022</h3>
<ul>
  <li>Probabilistic Plan Recognition using off-the-shelf Classical Planners <a href="https://www.dtic.upf.edu/~hgeffner/pr-aaai-2010.pdf">[link]</a></li>
</ul>

<h3 id="10182022">10/18/2022</h3>
<ul>
  <li>Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning <a href="https://arxiv.org/abs/2210.05492">[link]</a></li>
  <li>Modeling Strong and Human-Like Gameplay with KL-Regularized Search <a href="https://arxiv.org/abs/2112.07544">[link]</a></li>
</ul>

<h3 id="10172022">10/17/2022</h3>
<ul>
  <li>Human-Level Performance in No-Press Diplomacy via Equilibrium Search <a href="https://arxiv.org/abs/2010.02923">[link]</a></li>
  <li>No Press Diplomacy: Modeling Multi-Agent Gameplay <a href="https://arxiv.org/abs/1909.02128">[link]</a></li>
</ul>

<h3 id="10112022">10/11/2022</h3>
<ul>
  <li>Policy Gradient Bayesian Robust Optimization for Imitation Learning <a href="https://arxiv.org/abs/2106.06499">[link]</a></li>
</ul>

<h3 id="10102022">10/10/2022</h3>
<ul>
  <li>Bayesian Inverse Reinforcement Learning <a href="https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-416.pdf">[link]</a></li>
</ul>

<h3 id="9192022">9/19/2022</h3>
<ul>
  <li>Experimental Study of Inequality and Unpredictability in an Artificial Cultural Market <a href="https://www.science.org/doi/10.1126/science.1121066">[link]</a></li>
</ul>

<h3 id="9182022">9/18/2022</h3>
<ul>
  <li>An Extensible Interactive Interface for Reward Design <a href="https://arxiv.org/abs/1906.02641">[link]</a></li>
</ul>

<h3 id="9172022">9/17/2022</h3>
<ul>
  <li>Social Simulacra: Creating Populated Prototypes for Social Computing Systems <a href="https://arxiv.org/abs/2208.04024">[link]</a></li>
</ul>

<h3 id="9132022">9/13/2022</h3>
<ul>
  <li>Retrospective on the 2021 BASALT Competition on Learning From Human Feedback <a href="https://arxiv.org/abs/2204.07123">[link]</a></li>
</ul>

<h3 id="9122022">9/12/2022</h3>
<ul>
  <li>Learning with Not Enough Data Part 3: Data Generation <a href="https://lilianweng.github.io/posts/2022-04-15-data-gen/">[link]</a></li>
</ul>

<h3 id="9102022">9/10/2022</h3>
<ul>
  <li>Simulators on Lesswrong <a href="https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators">[link]</a></li>
</ul>

<h3 id="952022">9/5/2022</h3>
<ul>
  <li>Trust Region Policy Optimization <a href="https://arxiv.org/abs/1502.05477">[link]</a></li>
</ul>

<h3 id="8292022">8/29/2022</h3>
<ul>
  <li>Reward-rational (implicit) choice: A unifying formalism for reward learning <a href="https://arxiv.org/abs/2002.04833">[link]</a></li>
  <li>The MineRL BASALT Competition on Learning from Human Feedback <a href="https://arxiv.org/abs/2107.01969">[link]</a></li>
</ul>

<h3 id="8282022">8/28/2022</h3>
<ul>
  <li>Active Preference-Based Learning of Reward Functions <a href="https://rss2017.lids.mit.edu/program/papers/04/">[link]</a></li>
</ul>

<h3 id="8242022">8/24/2022</h3>
<ul>
  <li>Deep Reinforcement Learning from Human Preferences <a href="https://arxiv.org/abs/1706.03741">[link]</a></li>
</ul>

<h3 id="8162022">8/16/2022</h3>
<ul>
  <li>Too many cooks: Bayesian inference for coordinating multi-agent collaboration <a href="https://arxiv.org/abs/2003.11778">[link]</a></li>
</ul>

<h3 id="8152022">8/15/2022</h3>
<ul>
  <li>Open Problems in Cooperative AI <a href="https://arxiv.org/abs/2012.08630">[link]</a></li>
</ul>

<h3 id="8112022">8/11/2022</h3>
<ul>
  <li>Distribution-Free Predictive Inference for Regression <a href="https://arxiv.org/abs/1604.04173">[link]</a></li>
  <li>Aaditya Ramdas’ Tutorial Talk on Conformal Prediction <a href="https://synapse.math.univ-toulouse.fr/s/KDcWmmU9j9zk0rm">[link]</a></li>
</ul>

<h3 id="8102022">8/10/2022</h3>
<ul>
  <li>Improving Reproducibility in Machine Learning Research <a href="https://www.jmlr.org/papers/volume22/20-303/20-303.pdf">[link]</a></li>
</ul>

<h3 id="892022">8/9/2022</h3>
<ul>
  <li>A tutorial on conformal prediction <a href="https://arxiv.org/abs/0706.3188">[link]</a></li>
</ul>

<h3 id="862022">8/6/2022</h3>
<ul>
  <li>Beyond Bayesian and Frequentists <a href="https://jsteinhardt.stat.berkeley.edu/files/stats-essay.pdf">[link]</a></li>
</ul>

<h3 id="5202022">5/20/2022</h3>
<ul>
  <li>The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision <a href="https://arxiv.org/abs/1904.12584">[link]</a></li>
</ul>

<h3 id="5192022">5/19/2022</h3>
<ul>
  <li>Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding <a href="https://arxiv.org/abs/1810.02338v2">[link]</a></li>
</ul>

<h3 id="5182022">5/18/2022</h3>
<ul>
  <li>Curiosity-driven Exploration by Self-supervised Prediction <a href="https://arxiv.org/abs/1705.05363">[link]</a></li>
  <li>VIME: Variational Information Maximizing Exploration <a href="https://arxiv.org/abs/1605.09674">[link]</a></li>
</ul>

<h3 id="5172022">5/17/2022</h3>
<ul>
  <li>Adaptive Computation Time for Recurrent Neural Networks <a href="https://arxiv.org/abs/1603.08983">[link]</a></li>
</ul>

<h3 id="5162022">5/16/2022</h3>
<ul>
  <li>Embodied Question Answering <a href="https://arxiv.org/abs/1711.11543">[link]</a></li>
</ul>

<h3 id="5132022">5/13/2022</h3>
<ul>
  <li>Global Convergence of Non-Convex Gradient Descent for Computing Matrix Squareroot <a href="https://arxiv.org/abs/1507.05854">[link]</a></li>
</ul>

<h3 id="5112022">5/11/2022</h3>
<ul>
  <li>Convolutional Dynamic Alignment Networks for Interpretable Classifications <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Bohle_Convolutional_Dynamic_Alignment_Networks_for_Interpretable_Classifications_CVPR_2021_paper.html">[link]</a></li>
  <li>Optimizing for Interpretability in Deep Neural Networks with Tree Regularization <a href="https://arxiv.org/abs/1908.05254">[link]</a></li>
  <li>Explainable Models with Consistent Interpretations <a href="https://www.aaai.org/AAAI21Papers/AAAI-8236.PillaiV.pdf">[link]</a></li>
</ul>

<h3 id="4272022">4/27/2022</h3>
<ul>
  <li>The Complexity of Agreement <a href="https://arxiv.org/abs/cs/0406061">[link]</a></li>
  <li>Superintelligence: Paths, Dangers, Strategies <a href="https://www.amazon.com/Superintelligence-Nick-Bostrom-audiobook/dp/B00LPMFE9Y/ref=sr_1_1?crid=KS4UJT5DNQX4&amp;keywords=superintelligence+by+nick+bostrom&amp;qid=1651103959&amp;s=books&amp;sprefix=superintellige%2Cstripbooks%2C56&amp;sr=1-1">[link]</a></li>
</ul>

<h3 id="4252022">4/25/2022</h3>
<ul>
  <li>Geometric Deep Learning - Grids, Groups, Graphs, Geodesics, and Gauges: Chapters 4.1, 5.3, 5.4 <a href="https://arxiv.org/abs/2104.13478">[link]</a></li>
</ul>

<h3 id="4242022">4/24/2022</h3>
<ul>
  <li>Adversarial Examples Are Not Bugs, They Are Features <a href="https://arxiv.org/abs/1905.02175">[link]</a></li>
</ul>

<h3 id="4232022">4/23/2022</h3>
<ul>
  <li>Image Synthesis with a Single (Robust) Classifier <a href="https://arxiv.org/abs/1906.09453">[link]</a></li>
  <li>Agreeing to Disagree <a href="https://www.jstor.org/stable/2958591?seq=1">[link]</a></li>
</ul>

<h3 id="4182022">4/18/2022</h3>
<ul>
  <li>Identifying Statistical Bias in Dataset Replication <a href="https://arxiv.org/abs/2005.09619">[link]</a></li>
</ul>

<h3 id="4162022">4/16/2022</h3>
<ul>
  <li>What Can Neural Networks Reason About? <a href="https://arxiv.org/abs/1905.13211">[link]</a></li>
</ul>

<h3 id="4152022">4/15/2022</h3>
<ul>
  <li>Cooperative Inverse Reinforcement Learning <a href="https://arxiv.org/abs/1606.03137">[link]</a></li>
  <li>Editing a classifier by rewriting its prediction rules <a href="https://arxiv.org/abs/2112.01008">[link]</a></li>
</ul>

<h3 id="4112022">4/11/2022</h3>
<ul>
  <li>Geometric Deep Learning - Grids, Groups, Graphs, Geodesics, and Gauges, Chapters 1-3 <a href="https://arxiv.org/abs/2104.13478">[link]</a></li>
</ul>

<h3 id="492022">4/9/2022</h3>
<ul>
  <li>The Old Man and the Sea by Ernest Hemingway</li>
</ul>

<h3 id="3282022">3/28/2022</h3>
<ul>
  <li>Convergence Analysis of Two-layer Neural Networks with ReLU Activation <a href="https://arxiv.org/abs/1705.09886">[link]</a></li>
</ul>

<h3 id="372022">3/7/2022</h3>
<ul>
  <li>A Gentle Introduction to Graph Neural Networks <a href="https://distill.pub/2021/gnn-intro/">[link]</a></li>
  <li>A General Formula on the Conjugate of the Difference of Functions <a href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7196EF8645D0C8C3D708C0CB59CBC629/S0008439500023547a.pdf/a-general-formula-on-the-conjugate-of-the-difference-of-functions.pdf">[link]</a></li>
  <li>Generalized Convexity and Fractional Programming with Economic Applications: On Strongly Convex and Paraconvex Dualities <a href="https://link.springer.com/book/10.1007/978-3-642-46709-7">[link]</a></li>
</ul>

<h3 id="352022">3/5/2022</h3>
<ul>
  <li>Group Equivariant Convolutional Networks <a href="https://arxiv.org/abs/1602.07576">[link]</a></li>
</ul>

<h3 id="322022">3/2/2022</h3>
<ul>
  <li>Model Inversion Networks for Model-Based Optimization <a href="https://arxiv.org/abs/1912.13464">[link]</a></li>
  <li>Conservative Objective Models for Effective Offline Model-Based Optimization <a href="https://arxiv.org/abs/2107.06882">[link]</a></li>
</ul>

<h3 id="312022">3/1/2022</h3>
<ul>
  <li>Consequences of Misaligned AI <a href="https://arxiv.org/abs/2102.03896">[link]</a></li>
  <li>Future of Life Institute AI Alignment Podcast: Inverse Reinforcement Learning and Inferring Human Preferences with Dylan Hadfield-Menell <a href="https://futureoflife.org/2019/01/17/cooperative-inverse-reinforcement-learning-with-dylan-hadfield-menell/">[link]</a></li>
</ul>

<h3 id="2212022">2/21/2022</h3>
<ul>
  <li>A unified framework for Hamiltonian deep neural networks <a href="https://arxiv.org/abs/2104.13166">[link]</a></li>
  <li>Stable Architectures for Deep Neural Networks <a href="https://arxiv.org/abs/1705.03341">[link]</a></li>
</ul>

<h3 id="2172022">2/17/2022</h3>
<ul>
  <li>Rationality AI to Zombies: How to Actually Change Your Mind <a href="https://www.lesswrong.com/rationality">[link]</a></li>
  <li>Generally Intelligent #10: Dylan Hadfield-Menell, UC Berkeley/MIT, on the value alignment problem in AI <a href="https://generallyintelligent.ai/podcast/2021-05-11-podcast-episode-10-dylan-hadfield-menell/">[link]</a></li>
</ul>

<h3 id="2152022">2/15/2022</h3>
<ul>
  <li>Algorithms for Inverse Reinforcement Learning <a href="https://ai.stanford.edu/~ang/papers/icml00-irl.pdf">[link]</a></li>
</ul>

<h3 id="2142022">2/14/2022</h3>
<ul>
  <li>Training language models to follow instructions with human feedback <a href="https://cdn.openai.com/papers/Training_language_models_to_follow_instructions_with_human_feedback.pdf">[link]</a></li>
  <li>Noisy Adaptive Group Testing using Bayesian Sequential Experimental Design <a href="https://arxiv.org/abs/2004.12508">[link]</a></li>
  <li>Towards a Rigorous Science of Interpretable Machine Learning <a href="https://arxiv.org/abs/1702.08608">[link]</a></li>
</ul>

<h3 id="2132022">2/13/2022</h3>
<ul>
  <li>Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV) <a href="https://arxiv.org/abs/1711.11279">[link]</a></li>
  <li>Concept Whitening for Interpretable Image Recognition <a href="https://arxiv.org/abs/2002.01650">[link]</a></li>
  <li>NBDT: Neural-Backed Decision Trees <a href="https://arxiv.org/abs/2004.00221">[link]</a></li>
</ul>

<h3 id="2122022">2/12/2022</h3>
<ul>
  <li>Rationality AI to Zombies: Map and Territory <a href="https://www.lesswrong.com/rationality">[link]</a></li>
</ul>

<h3 id="292022">2/9/2022</h3>
<ul>
  <li>Poincaré Embeddings for Learning Hierarchical Representations <a href="https://arxiv.org/abs/1705.08039">[link]</a></li>
</ul>

<h3 id="242022">2/4/2022</h3>
<ul>
  <li>This Looks Like That: Deep Learning for Interpretable Image Recognition <a href="https://arxiv.org/abs/1806.10574">[link]</a></li>
  <li>Towards Robust Interpretability with Self-Explaining Neural Networks <a href="https://arxiv.org/abs/1806.07538">[link]</a></li>
</ul>

<h3 id="1312022">1/31/2022</h3>
<ul>
  <li>A Unified Approach to Interpreting Model Predictions <a href="https://arxiv.org/abs/1705.07874">[link]</a></li>
</ul>

<h3 id="1102022">1/10/2022</h3>
<ul>
  <li>Concept Bottleneck Models <a href="https://arxiv.org/abs/2007.04612">[link]</a></li>
</ul>

<h3 id="132022">1/3/2022</h3>
<ul>
  <li>Why Should I Trust You? Explaining the Predictions of Any Classifier <a href="https://arxiv.org/abs/1602.04938">[link]</a></li>
  <li>How to Explain Individual Classification Decisions <a href="https://www.jmlr.org/papers/volume11/baehrens10a/baehrens10a.pdf">[link]</a></li>
  <li>How to Explain the Prediction of a Machine Learning Model <a href="https://lilianweng.github.io/lil-log/2017/08/01/how-to-explain-the-prediction-of-a-machine-learning-model.html">[link]</a></li>
</ul>

<h3 id="12282021">12/28/2021</h3>
<ul>
  <li>Learning Structured Output Representation using Deep Conditional Generative Models <a href="https://papers.nips.cc/paper/2015/file/8d55a249e6baa5c06772297520da2051-Paper.pdf">[link]</a></li>
</ul>

<h3 id="12272021">12/27/2021</h3>
<ul>
  <li>Genesis 1-7</li>
</ul>

<h3 id="12252021">12/25/2021</h3>
<ul>
  <li>Accelerating Rescaled Gradient Descent: Fast Optimization of Smooth Functions <a href="https://arxiv.org/abs/1902.08825">[link]</a></li>
</ul>

<h3 id="12232021">12/23/2021</h3>
<ul>
  <li>Tensor Algebra and Tensor Analysis for Engineers, Chapter 1: Vectors and Tensors in a Finite-Dimensional Space <a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-16342-0.pdf">[link]</a></li>
</ul>

<h3 id="12222021">12/22/2021</h3>
<ul>
  <li>Dual Space Preconditioning for Gradient Descent <a href="https://arxiv.org/abs/1902.02257v4">[link]</a></li>
</ul>

<h3 id="12212021">12/21/2021</h3>
<ul>
  <li>Generally Intelligent #12: Jacob Steinhardt, UC Berkeley, on machine learning safety, alignment and measurement <a href="https://generallyintelligent.ai/podcast/2021-06-17-podcast-episode-12-jacob-steinhardt/">[link]</a></li>
</ul>

<h3 id="12202021">12/20/2021</h3>
<ul>
  <li>Monte Carlo Statistical Methods, Chapter 6: Markov Chains <a href="https://mcube.lab.nycu.edu.tw/~cfung/docs/books/robert2004monte_carlo_statistical_methods.pdf">[link]</a></li>
</ul>]]></content><author><name>Stewart Slocum</name></author><summary type="html"><![CDATA[List of things I’ve been reading. Only adding things that I’ve read thoroughly and understand beyond a superficial level.]]></summary></entry><entry><title type="html">Hutchinson’s Diagonal Estimator</title><link href="http://localhost:4000/2021/08/07/hutchinson's-diagonal-estimator.html" rel="alternate" type="text/html" title="Hutchinson’s Diagonal Estimator" /><published>2021-08-07T00:00:00-04:00</published><updated>2021-08-07T00:00:00-04:00</updated><id>http://localhost:4000/2021/08/07/hutchinson&apos;s-diagonal-estimator</id><content type="html" xml:base="http://localhost:4000/2021/08/07/hutchinson&apos;s-diagonal-estimator.html"><![CDATA[<blockquote>
  <p>In this post, we’ll take a look at a method of approximating large Hessian matrices using a stochastic diagonal estimator. Hutchinson’s method can be used for optimization and loss-landscape analysis in deep neural networks.</p>
</blockquote>

<!--more-->

<p>In modern machine learning with large deep models, explicit computation of the Hessian matrix is intractable. However, the Hessian matrix provides valuable information for optimization, studying generalization, and for other purposes. But even if we can’t calculate the full Hessian, can we effectively approximate it?</p>

<p><img src="/assets/images/flat-minimum.png" alt="Neural Network Loss Surfaces" /> <em>Fig. 1. Flat minima have been linked to improved generalization. The magnitude of the eigenvalues of the Hessian provide one way to characterize sharpness/flatness <a class="citation" href="#Keskar2017OnLT">(Keskar et al., 2017)</a>.</em></p>

<p>There has been significant work towards efficient approximation of the Hessian, most notably in the form of low-rank updates like <a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS">L-BFGS</a>. This approach work well in traditional optimization settings, but is relatively slow and generally doesn’t work in stochastic settings <a class="citation" href="#bollapragada2018progressive">(Bollapragada et al., 2018)</a>.</p>

<p>Alternatively, there has also been a variety of work old and new to estimate the diagonal of the Hessian as a way of approximating the matrix as a whole, for pruning <a class="citation" href="#LeCun1989OptimalBD">(LeCun et al., 1989)</a>, <a class="citation" href="#Hassibi1992SecondOD">(Hassibi &amp; Stork, 1992)</a> analyzing the loss landscape <a class="citation" href="#Yao2020PyHessianNN">(Yao et al., 2020)</a>, and optimization <a class="citation" href="#Yao2021ADAHESSIANAA">(Yao et al., 2021)</a>. It has been argued that the diagonal is a good approximation to the Hessian for machine learning problems, and that diagonal elements tend to be much larger than off-diagonal elements.</p>

<p>However, calculating the diagonal of the Hessian is not straightforward. Automatic differentiation libraries are designed to make large computations in parallel, so naively calculating diagonal terms of the Hessian one-by-one \(\frac{\partial^2 L(x)}{\partial x_1^2}, \frac{\partial^2 L(x)}{\partial x_2^2}, ..., \frac{\partial^2 L(x)}{\partial x_n^2}\) requires \(n\) backprop operations and isn’t computationally feasible. However, we can estimate this diagonal relatively efficiently using randomized linear algebra in the form of Hutchinson’s estimator.</p>

<h2 id="hessian-vector-products">Hessian-Vector Products</h2>

<p>While calculating the Hessian as a whole isn’t possible, we <em>can</em> efficiently estimate Hessian-vector products. There are a variety of ways to do this, the simplest being a finite difference approximation:</p>

<h3 id="1-finite-difference-approximation">1. Finite Difference Approximation</h3>

\[H(x) v \approx \frac{g(x + rv) - g(x - rv)}{2r}\]

<p>The error of this approximation is \(O(r)\), which means it can be quite accurate when \(r\) is small. However, as \(r\) becomes small, rounding errors pile up in the numerator. While not accurate enough for every application, the finite difference approximation is simple and cheap (2 gradient evaluations).</p>

<h3 id="2-product-rule-trick">2. Product Rule Trick</h3>

\[\frac{\partial (g(x)^\top v)}{\partial x} = \frac{\partial g(x)}{\partial x} v + g(x) \frac{\partial v}{\partial x} = \frac{\partial g(x)}{\partial x} v = H(x) v\]

<p>This exact method requires taking the gradient of an expression that includes the gradient. It means that the operations used to backprop must also be tracked so they can be differentiated. This method is also \(O(n)\) like typical gradient evaluations, but because of the more complex underlying expression, the constant factors are slightly higher in memory and in time. The product rule trick is the implementation you’ll find for Hessian-vector products in <a href="https://pytorch.org/docs/stable/generated/torch.autograd.functional.vhp.html#torch.autograd.functional.vhp">pytorch</a> and <a href="https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html">jax</a>.</p>

<h2 id="hutchinsons-estimator">Hutchinson’s Estimator</h2>

<p>Now that we have efficient Hessian-vector multiplication, we can use Hutchinson’s estimator.</p>

<h3 id="hutchinsons-trace-estimator">Hutchinson’s Trace Estimator</h3>

<p>Hutchinson’s original estimator is for the trace of a matrix. This estimator is more common than the diagonal estimator and has been more thoroughly analyzed, so let’s warm up by taking a look at it.</p>

<p>To estimate the trace, we draw random vectors \(z\) from a distribution with mean zero and variance one (typically the <a href="https://en.wikipedia.org/wiki/Rademacher_distribution">Rademacher distribution</a>). We can then estimate the trace of a matrix as \(\mathbb{E}[z^\top H z] = \text{trace}(H)\).</p>

<p><strong>Theorem:</strong> Let \(z\) a random vector with \(\mathbb{E}[z]=0\), \(\mathbb{V}[z]=1\), and independent entries. Then \(\mathbb{E}[z^\top H z] = \text{trace}(H)\).</p>

<p><em>Proof.</em></p>

\[\begin{align}
	\mathbb{E}[z^\top H z] &amp;= \mathbb{E}[\begin{bmatrix}z_1 \\ z_2 \\ ... \\ z_n\end{bmatrix}^\top \begin{bmatrix}H_{11} z_1 + H_{12} z_2 + ... + H_{1n} z_n \\ H_{12} z_1 + H_{22} z_2 + ... + H_{2n} z_n \\ ... \\ H_{n1} z_1 + H_{n2} z_2 + ... + H_{nn} z_n\end{bmatrix}] \\
	&amp;= \mathbb{E}[\begin{bmatrix}z_1 \\ z_2 \\ ... \\ z_n\end{bmatrix}^\top \begin{bmatrix}\sum\limits_{i=1}^n H_{1i} z_i \\ \sum\limits_{i=1}^n H_{2i} z_i \\ ... \\ \sum\limits_{i=1}^n H_{ni} z_i\end{bmatrix}] \\
	&amp;= \mathbb{E}[z_1 \sum\limits_{i=1}^n H_{1i} z_i + z_2 \sum\limits_{i=1}^n H_{2i} z_i + ... + z_n \sum\limits_{i=0}^n H_{ni} z_i] \\
	&amp;= \sum\limits_{i=1}^n H_{1i} \mathbb{E}[z_1 z_i] + \sum\limits_{i=1}^n H_{2i} \mathbb{E}[z_2 z_i] + ... + \sum\limits_{i=1}^n H_{ni} \mathbb{E}[z_n z_i] \\
\end{align}\]

<p>And since the entries of \(z\) are independent, \(\mathbb{E}[z_i z_j] = \mathbb{E}[z_i]\mathbb{E}[z_j] = 0 \cdot 0 = 0\) for \(i \neq j\).</p>

<p>However, when \(i = j\), then \(\mathbb{E}[z_i z_j] = \mathbb{E}[z_i^2] = \mathbb{V}[z_i] + \mathbb{E}[z_i]^2 = 1 + 0^2 = 1\).</p>

<p>So</p>

\[\begin{align}
  \mathbb{E}[z^\top H z] &amp;= \sum\limits_{i=1}^n H_{1i} \mathbb{E}[z_1 z_i] + \sum\limits_{i=1}^n H_{2i} \mathbb{E}[z_2 z_i] + ... + \sum\limits_{i=1}^n H_{ni} \mathbb{E}[z_n z_i] \\
  &amp;= H_{11} + H_{22} + ... + H_{nn} \\
  &amp;= \text{trace}(H) \tag*{$\blacksquare$}
\end{align}\]

<h3 id="hutchinsons-diagonal-estimator">Hutchinson’s Diagonal Estimator</h3>

<p>The basic idea from the trace estimator can be modified to give an estimator for the diagonal rather than the trace.</p>

<p><strong>Theorem:</strong> Let \(z\) be a random variable \(z\) with \(\mathbb{E}[z]=0\), \(\mathbb{V}[z]=1\), and independent entries. Then \(\mathbb{E}[z \odot H z] = \text{diag}(H)\).</p>

<p><em>Proof.</em></p>

\[\begin{align*}
    \mathbb{E}[z \odot Hz] &amp;= \mathbb{E}[
    \begin{bmatrix}z_1 \\ z_2 \\ ... \\ z_n\end{bmatrix} \odot
    \begin{bmatrix}
    H_{11} z_1 + H_{12} z_2 + ... + H_{1n} z_n \\
    H_{21} z_1 + H_{22} z_2 + ... + H_{2n} z_n \\ ... \\
    H_{n1} z_1 + H_{n2} z_2 + ... + H_{nn} z_n
    \end{bmatrix}
    ] \\
    &amp;= \begin{bmatrix}
    H_{11} \mathbb{E}[z_1^2] + H_{12} \mathbb{E}[z_1z_2] + ... + H_{1n}[z_1z_n] \\
    H_{21} \mathbb{E}[z_2z_1] + H_{22} \mathbb{E}[z_2^2] + ... + H_{2n}[z_2z_n] \\ ... \\
    H_{n1} \mathbb{E}[z_nz_1] + H_{n2} \mathbb{E}[z_nz_2] + ... + H_{nn}[z_n^2]
    \end{bmatrix} \\
    &amp;= \begin{bmatrix}
    H_{11} \\ H_{22} \\ ... \\ H_{nn}
    \end{bmatrix} \\
    &amp;= \text{diag}(H) \tag*{$\blacksquare$}
\end{align*}\]

<p>Now let’s calculate the variance of Hutchinson’s diagonal estimator.</p>

<p><strong>Theorem:</strong> Let \(z \sim \text{Rademacher}\). Then the covariance matrix of Hutchinson’s diagonal estimator is</p>

\[\begin{align}
    \Sigma_{z \odot Hz} = \text{diag}(H)\text{diag}(H)^\top + \left(\begin{bmatrix}
    ||H_1||^2 \\
    ||H_2||^2 \\
    \vdots \\
    ||H_n||^2
    \end{bmatrix} - 2 \text{diag}(H)^2\right) \odot I
\end{align}\]

<p>where \(H_i\) is the \(i\)-th row of \(H\).</p>

<p><em>Proof.</em> Let us consider each entry of the covariance matrix separately:</p>

\[\begin{align}
    (\Sigma_{z \odot Hz})_{ij} &amp;= \text{Cov}[(z \odot Hz)_i (z \odot Hz)_j] \\
    &amp;= \mathbb{E}[(z \odot Hz)_i (z \odot Hz)_j] - \mathbb{E}[z \odot Hz]_i \mathbb{E}[z \odot Hz]_j \\
    &amp;= \mathbb{E}[(z_i (H_{i1} z_1 + ... + H_{in} z_n)) (z_j (H_{j1} z_1 + ... + H_{jn} z_n))] - H_{ii} H_{jj} \\
    &amp;= \mathbb{E}[\sum\limits_{k=0}^n \sum\limits_{l=0}^n H_{ik}H_{jl} z_i z_k z_j z_l] - H_{ii}H_{jj} \\
    &amp;= (\sum\limits_{k=0}^n \sum\limits_{l=0}^n H_{ik} H_{jl} \mathbb{E}[z_i z_k z_j z_l]) - H_{ii}H_{jj}
\end{align}\]

<p>First consider diagonal elements, which have \(i = j\):</p>
<ol>
  <li>Case 1. \(i = j = k = l\). Then \(\mathbb{E}[z_i z_k z_j z_l] = \mathbb{E}[z_i^4] = \text{Kurtosis}[z]\)</li>
  <li>Case 2. \(i = j \neq k\), \(k = l\). Then \(\mathbb{E}[z_i z_k z_j z_l] = \mathbb{E}[z_i^2]\mathbb{E}[z_k^2] = 1 \cdot 1 = 1\)</li>
  <li>Case 3. \(i = j\), \(k \neq l\). Therefore, at least one of \(k, l \neq i\). WLOG suppose \(k \neq i\). Then \(\mathbb{E}[z_i z_k z_j z_l] = \mathbb{E}[z_i^2 z_l]\mathbb{E}[z_k] = 0 \cdot \mathbb{E}[z_i^2 z_l] = 0\)</li>
</ol>

<p>This gives</p>

\[\begin{align}
    (\Sigma_{z \odot Hz})_{ii} &amp;= (\sum\limits_{k=0}^n \sum\limits_{l=0}^n H_{ik} H_{il} \mathbb{E}[z_i z_k z_i z_l]) - H_{ii}^2 \\
    &amp;= \text{Kurtosis}[z]H_{ii}^2 +  \sum\limits_{k=0, k \neq i}^n H_{ik}^2 - H_{ii}^2 \\
    &amp;= \sum\limits_{k=0, k \neq i}^n H_{ik}^2
\end{align}\]

<p>since the kurtosis of a Rademacher RV is 1. In fact, the Bernoulli distribution has the smallest kurtosis of any distribution at 1, and since the Rademacher distribution is just a scaled Bernoulli, it is the optimal distribution to draw \(z\) from with respect to the variance of our estimator.</p>

<p>Now consider off-diagonal elements, which have \(i \neq j\):</p>
<ol>
  <li>Case 1. \(i \neq j\) with \(i = k, j = l\) or \(i = l, j = k\). Then \(\mathbb{E}[z_i z_k z_j z_l] = \mathbb{E}[z_i^2]\mathbb{E}[z_j]^2 = 1 \cdot 1 = 1\)</li>
  <li>Case 2. \(i \neq j\) with at least one of \(k, l\) not equal to \(i\) or \(j\). WLOG suppose \(k \neq i, j\). Then \(\mathbb{E}[z_i z_k z_j z_l] = \mathbb{E}[z_i z_j z_l]\mathbb{E}[z_k] = \mathbb{E}[z_i z_j z_l] \cdot 0 = 0\)</li>
</ol>

<p>This gives</p>

\[\begin{align}
    (\Sigma_{z \odot Hz})_{ij} &amp;= (\sum\limits_{k=0}^n \sum\limits_{l=0}^n H_{ik} H_{jl} \mathbb{E}[z_i z_k z_j z_l]) - H_{ii}H_{jj} \\
    &amp;= 2H_{ii}H_{jj} - H_{ii}H_{jj} \\
    &amp;= H_{ii}H_{jj}
\end{align}\]

<p>So our final covariance matrix is</p>

\[\require{color}
\definecolor{brand}{RGB}{78, 182, 133}
\begin{align}
    \Sigma_{z \odot Hz} &amp;=
    \begin{bmatrix}
        \textcolor{brand}{\sum\limits_{k=0, k \neq 1}^n H_{1k}^2} &amp; H_{11}H_{22} &amp; H_{11}H_{33} &amp; ... &amp; H_{11}H_{nn} \\
        H_{11}H_{22} &amp; \textcolor{brand}{\sum\limits_{k=0, k \neq 2}^n H_{2k}^2} &amp; H_{22}H_{33} &amp; ... &amp; H_{22}H_{nn} \\
        H_{11}H_{33} &amp; H_{22}H_{33} &amp; \textcolor{brand}{\sum\limits_{k=0, k \neq 3}^n H_{3k}^2} &amp; ... &amp; H_{33}H_{nn} \\
        \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; H_{n-1n-1}H_{nn} \\
        H_{11}H_{nn} &amp; H_{22}H_{nn} &amp; H_{33}H_{nn} &amp; ... &amp; \textcolor{brand}{\sum\limits_{k=0, k \neq n}^n H_{nk}^2}
    \end{bmatrix} \\
    &amp;= \underbrace{\text{diag}(H)\text{diag}(H)^\top - \text{diag}(H)^2 \odot I}_{\text{off-diagonal covariances}} + \underbrace{\textcolor{brand}{\left(\begin{bmatrix}
    ||H_1||^2 \\
    ||H_2||^2 \\
    \vdots \\
    ||H_n||^2
    \end{bmatrix} - \text{diag}(H)^2\right) \odot I}}_{\text{diagonal vector of variances}} \\
    &amp;= \text{diag}(H)\text{diag}(H)^\top + \left(\begin{bmatrix}
    ||H_1||^2 \\
    ||H_2||^2 \\
    \vdots \\
    ||H_n||^2
    \end{bmatrix} - 2 \text{diag}(H)^2\right) \odot I \tag*{$\blacksquare$}
\end{align}\]

<p>Note that <em>variance</em> of our estimator (diagonal of tbe covariance matrix) at a specific output \(i\) is \(\mathbb{V}[(z \odot H z)_i] = \textcolor{brand}{\sum\limits_{k=0, k \neq i}^n H_{ik}^2} = \| H_i \| ^2 - H_{ii}^2\). Interestingly, this variance is equal to the squared L-2 norm of the off-diagonal elements of each row. So even though this variance grows like \(O(n)\) with the number of variables in the Hessian, if the assumption that the off-diagonal elements of the Hessian are small is true, then this variance remains small.
<br /><br /></p>

<hr />

<p><br />
Now let’s take a break with this landscape by Rembrandt</p>

<p><img src="/assets/images/the-mill.jpg" /></p>

<p class="center"><strong>The Mill</strong></p>

<p class="center">Courtesy National Gallery of Art, Washington</p>

<h2 id="references">References</h2>

<ol class="bibliography"><li><span id="Keskar2017OnLT">Keskar, N., Mudigere, D., Nocedal, J., Smelyanskiy, M., &amp; Tang, P. T. P. (2017). On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima. <i>ArXiv</i>, <i>abs/1609.04836</i>.</span></li>
<li><span id="bollapragada2018progressive">Bollapragada, R., Nocedal, J., Mudigere, D., Shi, H.-J., &amp; Tang, P. T. P. (2018). A progressive batching L-BFGS method for machine learning. <i>International Conference on Machine Learning</i>, 620–629. https://arxiv.org/abs/1802.05374</span></li>
<li><span id="LeCun1989OptimalBD">LeCun, Y., Denker, J., &amp; Solla, S. (1989). Optimal Brain Damage. <i>NIPS</i>.</span></li>
<li><span id="Hassibi1992SecondOD">Hassibi, B., &amp; Stork, D. (1992). Second Order Derivatives for Network Pruning: Optimal Brain Surgeon. <i>NIPS</i>.</span></li>
<li><span id="Yao2020PyHessianNN">Yao, Z., Gholami, A., Keutzer, K., &amp; Mahoney, M. W. (2020). PyHessian: Neural Networks Through the Lens of the Hessian. <i>2020 IEEE International Conference on Big Data (Big Data)</i>, 581–590.</span></li>
<li><span id="Yao2021ADAHESSIANAA">Yao, Z., Gholami, A., Shen, S., Keutzer, K., &amp; Mahoney, M. (2021). ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning. <i>ArXiv</i>, <i>abs/2006.00719</i>.</span></li></ol>]]></content><author><name>Stewart Slocum</name></author><category term="optimization" /><summary type="html"><![CDATA[In this post, we’ll take a look at a method of approximating large Hessian matrices using a stochastic diagonal estimator. Hutchinson’s method can be used for optimization and loss-landscape analysis in deep neural networks.]]></summary></entry></feed>